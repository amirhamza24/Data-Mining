{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Json File From Drive**"
      ],
      "metadata": {
        "id": "OHvmQ4hcUUSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "BaOMX_vQdeQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/DMKD"
      ],
      "metadata": {
        "id": "Rc0Q-c3lefXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import All libraries**"
      ],
      "metadata": {
        "id": "TSyL6bD7VHok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "xD2qqQ7VsKuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convert Json to CSV**"
      ],
      "metadata": {
        "id": "5-nUainEVw0K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XbEg-eH2Pfy"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Open the JSON file\n",
        "with open('/content/drive/MyDrive/DMKD/test.json', 'r') as json_file:\n",
        "    # Load the JSON data\n",
        "    data = json.load(json_file)\n",
        "\n",
        "# Open the CSV file\n",
        "with open('output.csv', 'w', newline='') as csv_file:\n",
        "    # Create a CSV writer\n",
        "    writer = csv.writer(csv_file)\n",
        "\n",
        "    # Write the headers\n",
        "    writer.writerow(data[0].keys())\n",
        "\n",
        "    # Write the data rows\n",
        "    for row in data:\n",
        "        writer.writerow(row.values())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/DMKD/output.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "l39PCyou1JoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre-Peocessed Data**"
      ],
      "metadata": {
        "id": "u16oPsXyV54y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file into a Pandas DataFrame\n",
        "df = pd.read_csv('/content/output.csv')\n",
        "\n",
        "# Extract the 'text' column from the DataFrame\n",
        "texts = df['post']\n",
        "\n",
        "# Initialize the NLTK tokenizer\n",
        "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "\n",
        "# Initialize a list to store the preprocessed texts\n",
        "processed_texts = []\n",
        "\n",
        "# Initialize a list of stopwords to remove\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# Initialize the Porter stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Iterate through the texts\n",
        "for post in texts:\n",
        "    # Tokenize the text\n",
        "    tokens = tokenizer.tokenize(str(post))\n",
        "    \n",
        "    # Remove punctuation and stopwords\n",
        "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words and token.isalpha()]\n",
        "    \n",
        "    # Stem the remaining tokens\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
        "    \n",
        "    # Join the tokens back into a single string\n",
        "    processed_text = ' '.join(stemmed_tokens)\n",
        "    \n",
        "    # Add the processed text to the list\n",
        "    processed_texts.append(processed_text)\n",
        "\n",
        "# Add the processed texts to the DataFrame as a new column\n",
        "df['processed_text'] = processed_texts\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file\n",
        "df.to_csv('processed_texts.csv', index=False)\n"
      ],
      "metadata": {
        "id": "p1nBIJEjUVe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file\n",
        "df = pd.read_csv('/content/drive/MyDrive/DMKD/processed_texts.csv')\n",
        "\n",
        "# Remove rows with missing data\n",
        "df = df.dropna()\n",
        "\n",
        "# Remove duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Remove post columns\n",
        "df = df.drop(columns=['post'])\n",
        "\n",
        "# Save the cleaned data to a new CSV file\n",
        "df.to_csv('processed_texts.csv', index=False)"
      ],
      "metadata": {
        "id": "V2TKkIaMDi4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/DMKD/processed_texts.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "U71X00-gEI6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file into a Pandas DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/DMKD/processed_texts.csv')\n",
        "\n",
        "# View the first few rows of the data\n",
        "print(df.head())\n",
        "\n",
        "# Get some basic statistics about the data\n",
        "print(df.describe())\n",
        "\n",
        "# Get information about the data types and number of non-null values in each column\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "Bjvg4Kv5L2c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Support Vector Model**"
      ],
      "metadata": {
        "id": "xdx3wunhWqXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from the CSV file into a DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/DMKD/processed_texts.csv')\n",
        "\n",
        "# Extract the text data and labels\n",
        "X = df['processed_text']\n",
        "y = df['gender']\n",
        "\n",
        "# Extract features from the text data using a CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(X)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "# Train a Suport Vector model\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the test set accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print('Test accuracy:', accuracy)\n"
      ],
      "metadata": {
        "id": "Fea9pWofMqij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic Regression Model**"
      ],
      "metadata": {
        "id": "op8ObE4YW0hL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the data from the CSV file into a DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/DMKD/processed_texts.csv')\n",
        "\n",
        "# Extract the text data and labels\n",
        "X = df['processed_text']\n",
        "y = df['gender']\n",
        "\n",
        "# Extract features from the text data using a CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(X)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid, verbose=2)\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid.best_params_)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the test set accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print('Test accuracy:', accuracy)\n"
      ],
      "metadata": {
        "id": "Xgkd9-KXYTdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision Tree Classifier Model**"
      ],
      "metadata": {
        "id": "vX9ej4EwXDJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from the CSV file into a DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/DMKD/processed_texts.csv')\n",
        "\n",
        "# Extract the text data and labels\n",
        "X = df['processed_text']\n",
        "y = df['gender']\n",
        "\n",
        "# Extract features from the text data using a CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(X)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "# Train a Decision Tree Classifier model\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the test set accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print('Test accuracy:', accuracy)\n"
      ],
      "metadata": {
        "id": "tUtFuUyeg7fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Naive Bayes Model**"
      ],
      "metadata": {
        "id": "Dllm7q-GXJ2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from the CSV file into a DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/DMKD/processed_texts.csv')\n",
        "\n",
        "# Extract the text data and labels\n",
        "X = df['processed_text']\n",
        "y = df['gender']\n",
        "\n",
        "# Extract features from the text data using a CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(X)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "# Train a Naive Bayes model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the test set accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "vfX4k5zZwhaO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}